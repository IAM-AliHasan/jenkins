import groovy.json.JsonOutput
import groovy.json.JsonSlurper
import java.text.SimpleDateFormat
import hudson.model.Actionable
import hudson.tasks.junit.CaseResult

def message = ""
def testSummary = ""
def date = new Date()
def sdf = new SimpleDateFormat("MM/dd/yyyy HH:mm:ss")
def slackNotificationChannel = "#hyly-ml-deployments"

def BUILD_TRIGGER_BY = "${currentBuild.getBuildCauses()[0].userId}"
def target_env = "qa"
def component = "sms-adapter"
def service_name = "smsadapter_qa"
def gcloud_project = "ml-dev-458608"
def gitCommitSHA
def branch = ""
def docker_repo = "hayley-ml-qa"
def bucket_name = "jenkins-artifact-storage-bucket"
def suspiciousFlags = []
// URL of the application to scan by ZAP
ZAP_CMD = "/opt/zaproxy/zap.sh"
def TARGET_URL = 'https://new-dev2-ml.hyly.us/sms_adapter_microservices/heartbeat' 
def auditLog = [
    scm: [:],
    docker: [:],
    cosign: [:],
    zap: [:],
    lint: [:],
    secrets: [:],
    pr_approval: [:],
    timestamps: [:],
    suspicious_activity: [flags: suspiciousFlags ]
]
        
def notifySlack(text, channel, attachments) {
    withCredentials([string(credentialsId: 'slack-webhook-url', variable: 'SLACK_URL')]) {
        def payload = JsonOutput.toJson([
            text       : text,
            channel    : channel,
            username   : "Jenkins",
            icon_emoji : ":jenkins:",
            attachments: attachments
        ])
         
        sh """
           curl -X POST --data-urlencode 'payload=${payload}' \$SLACK_URL
        """
    }
}

//Pipeline stages start

node {
    try {
        stage('SCM Pull') {
            checkout scm
            def gitCommit = sh(script: "git rev-parse HEAD", returnStdout: true).trim();
            gitCommitSHA = gitCommit.substring(0,7);
            //Below are the configs to populate the audit report
            auditLog.scm.sha = gitCommitSHA
            auditLog.scm.branch = branch
            auditLog.timestamps.scm_pull = sdf.format(date)
        }

        stage('Git Secrets Scan') {
            dir('demo-service') {
                // Run git-secrets to scan for secrets
                def scanResult = sh(script: '''
                    export TERM=dumb
                    git secrets --install -f
                    git secrets --register-aws
                                       
                    git secrets --add '"private_key":'
                    
                    git secrets --scan --verbose 2>/dev/null
                ''', returnStatus: true)  // Capture the exit code
                auditLog.secrets.scan_status = scanResult == 0 ? "PASS" : "FAIL"
                auditLog.timestamps.git_secrets_scan = sdf.format(new Date())

                // Check the exit code of the git-secrets scan
                if (scanResult != 0) {
                    echo "Git Secrets found sensitive data but proceeding with the build as per override."
                    sh "git secrets --scan"  // This will print out the found secrets in the build logs
                    suspiciousFlags << "Git secrets scan found sensitive data but build is continuing."
                    //error "Git Secrets found sensitive data in the repository. Build is failing!"
                }
            }
        }

        stage('Scan Dependencies') {
            dir('demo-service') {
                sh '''
                    trivy fs --severity HIGH,CRITICAL --exit-code 0 --skip-dirs .git .
                '''
            }
        }
        stage('Linting and Code Style Checks') {
            dir('demo-service') {
                sh '''
                    echo "[Lint] Running black format check..."
                    black --check . || {
                        echo "[Lint] Found code style issues. Showing diff:"
                        #black --diff .
                        echo "[Lint] ❗ Code is not formatted correctly."
                        echo "[Lint] Please run 'black .' locally and push the changes."
                        # Optional: exit 1 to enforce
                       # exit 1
                    }
                    echo "[Flake8] Running linter check..."
                    flake8 . || {
                        echo "[Flake8] ❗ Code quality issues detected."
                        echo "[Flake8] Suggestion: Run 'flake8 .' locally and fix issues."
                      # Optional: exit 1 to enforce
                      # exit 1
                    }
                
                '''
                //Below are the configs to populate the audit report
                auditLog.lint.black = "Executed"
                auditLog.lint.flake8 = "Executed"
                auditLog.timestamps.lint = sdf.format(new Date())
            }
        }
      
        
        stage('ZAP Security Scan') {
            sh """
                echo "[ZAP] Starting OWASP ZAP with xvfb..."
                nohup ${ZAP_CMD} -daemon -host 127.0.0.1 -port 8090 -config api.disablekey=true > zap.log 2>&1 &
                # Wait until ZAP is up and running
                for i in {1..30}; do
                echo "Checking if ZAP is up on port 8090... (Attempt \$i)"
                    if curl -s http://127.0.0.1:8090; then
                        echo "ZAP is ready."
                        break
                fi
                sleep 50
            done

                echo "[ZAP] Spider scanning ${TARGET_URL}..."
                curl "http://127.0.0.1:8090/JSON/spider/action/scan/?url=${TARGET_URL}&recurse=true"
                sleep 20

                echo "[ZAP] Active scanning ${TARGET_URL}..."
                curl "http://127.0.0.1:8090/JSON/ascan/action/scan/?url=${TARGET_URL}&recurse=true"
                sleep 30

                echo "[ZAP] Fetching HTML report..."
                curl "http://127.0.0.1:8090/OTHER/core/other/htmlreport/" -o zap_report.html
                #echo "[ZAP] Stopping ZAP..."
                #sudo pkill -f zap || true
            """
            //Below are the configs to populate the audit report
            auditLog.zap.url = TARGET_URL
            auditLog.zap.status = "Completed"
            auditLog.timestamps.zap_scan = sdf.format(new Date())
            archiveArtifacts artifacts: 'zap_report.html', allowEmptyArchive: true
        }


        stage('Login gcloud') {
            withCredentials([file(credentialsId: 'new-gcloud-creds-demo', variable: 'GCLOUD_CREDS')]) {
                sh """
                    gcloud auth activate-service-account --key-file=\$GCLOUD_CREDS
                    gcloud config unset auth/impersonate_service_account || true
                    gcloud config set project $gcloud_project
                """
            }
        }


        stage('Enforce PR Approval') {
            if (env.CHANGE_ID) {
                withCredentials([string(credentialsId: 'munishgandhi_gh_token', variable: 'GITHUB_TOKEN')]) {
                    def prNumber = env.CHANGE_ID
                    def repo = "munishgandhi/demo-service"
                    def apiUrl = "https://api.github.com/repos/${repo}/pulls/${prNumber}/reviews"
                    def approvalCount = sh(
                        script: """curl -s -H "Authorization: token ${GITHUB_TOKEN}" ${apiUrl} | jq '[.[] | select(.state=="APPROVED")] | length'""",
                        returnStdout: true
                    ).trim()
                    auditLog.pr_approval = [
                        pr_number: prNumber,
                        approved_count: approvalCount,
                        timestamp: sdf.format(date)
                    ]
                    

                    if (approvalCount.toInteger() < 1) {
                        auditLog.pr_approval.status = "NOT_APPROVED"
                        suspiciousFlags << "PR #${prNumber} proceeded without approval"
                        error("PR #${prNumber} has NOT been approved. Failing build.")
                    } else {
                        auditLog.pr_approval.status = "APPROVED"
                        echo "PR #${prNumber} is approved. Proceeding."
                    }
                }
            } else {
                auditLog.pr_approval = [
                    status: "SKIPPED",
                    reason: "Not a PR build",
                    timestamp: sdf.format(date)
                ]
            }
        }


        stage('Build Docker Image') {
            sshagent (credentials: ['jenkins-ssh']) {
                sh "gcloud auth configure-docker us-east1-docker.pkg.dev --quiet"
                // sh "docker build -t us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA ."
                sh "DOCKER_BUILDKIT=1 docker build --ssh default --network=host -t us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA -t us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:latest ."
                auditLog.docker.build_command = "docker build -t us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA ."
                auditLog.timestamps.docker_build = sdf.format(date)       
            }
        }

    /*
        stage('Scan Docker Image') {
            def image = "us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter_qa:$gitCommitSHA"
            sh """
                trivy image --scanners vuln --severity CRITICAL --exit-code 0 --format json -o trivy-report.json ${image} 
                
            """
            // Debugging: Output the content of image.html to verify it's correct
            sh "cat image.html"
            archiveArtifacts artifacts: 'trivy-report.json', allowEmptyArchive: true
            
        }
      */
        stage('Upload to Google Cloud Storage') {
            // Upload the trivy-report.json file to Google Cloud Storage
            withCredentials([file(credentialsId: 'new-gcloud-creds-demo', variable: 'My_GCLOUD_CREDS')]) {
                sh """
                    #gsutil cp trivy-report.json gs://${bucket_name}/trivy-reports/${gitCommitSHA}_trivy-report.json
                    #gsutil cp image.html gs://${bucket_name}/image/${gitCommitSHA}_image.html
                    gsutil cp zap_report.html gs://${bucket_name}/zap-reports/${gitCommitSHA}_zap_report.html
                
                    # Set the content type to text/html for the HTML file
                    #gsutil setmeta -h "Content-Type:text/html" gs://${bucket_name}/image/${gitCommitSHA}_image.html
                    gsutil setmeta -h "Content-Type:text/html" gs://${bucket_name}/zap-reports/${gitCommitSHA}_zap_report.html


                """
                
                
            }
        }

        stage('Push Docker Image') {
            def latestImage = "us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:latest"
            sh "docker push us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA"
            sh "docker push us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:latest"
            //sh "docker rmi us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter_qa:$gitCommitSHA us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter_qa:latest"
            // Capture digest before removing local image
            def taggedDigest = sh(
                script: "docker inspect --format='{{index .RepoDigests 0}}' ${latestImage}",
                returnStdout: true
            ).trim()

        // Save digest to file so next stage can access it
            writeFile file: 'image-digest.txt', text: taggedDigest
            sh "docker rmi us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:latest"
            auditLog.docker.push_command = "docker push us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA"
            auditLog.docker.digest = taggedDigest
            auditLog.timestamps.docker_push = sdf.format(date)
        }


        stage('Sign Docker Image with Cosign') {
            withCredentials([file(credentialsId: 'cosign-private-key', variable: 'COSIGN_KEY')]) {
                def image = "us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:$gitCommitSHA"
                def latestImage = "us-east1-docker.pkg.dev/$gcloud_project/$docker_repo/smsadapter:latest"
                def taggedDigest = readFile('image-digest.txt').trim()

                sh """
                    echo "[COSIGN] Signing Docker image by digest: ${taggedDigest}"
                    COSIGN_PASSWORD="" cosign sign --key \$COSIGN_KEY --yes ${taggedDigest}
                """
                auditLog.cosign.sign_command = "cosign sign --key \$COSIGN_KEY --yes ${taggedDigest}"
                auditLog.timestamps.cosign_sign = sdf.format(date)
            }
        }


        stage('Verify Docker Image Signature') {
            withCredentials([file(credentialsId: 'cosign-public-key', variable: 'COSIGN_PUB')]) {
                def taggedDigest = readFile('image-digest.txt').trim()

                sh """
                    echo "[COSIGN] Verifying signature for image: ${taggedDigest}"
                 cosign verify --key \$COSIGN_PUB ${taggedDigest}
                """
                auditLog.cosign.verify_command = "cosign verify --key \$COSIGN_PUB ${taggedDigest}"
                auditLog.timestamps.cosign_verify = sdf.format(date)
            }
        }


        stage('Manual Approval for Production') {
            input(
                message: 'Do you approve deploying to production?',
                ok: 'Deploy',
                submitter: 'admin'
            )
        }
        stage('Run docker container') {
            sshagent (credentials: ['jenkins-ssh']) {
                sh """
                    ssh -o StrictHostKeyChecking=no ubuntu@hayley-qa-stg-ml '
                        cd ~/hayleyQA
                        gcloud auth print-access-token | docker login -u oauth2accesstoken --password-stdin https://us-east1-docker.pkg.dev
                        docker compose pull ${service_name}
                        docker compose up -d --no-deps --build ${service_name}
                        echo y | docker image prune -a
                    '
                """
            }
        }


        stage('Slack notification') {
            def buildColor = currentBuild.result == null ? "good" : "warning"
            def buildStatus = currentBuild.result == null ? "Success" : currentBuild.result
            def jobName = "${env.JOB_NAME}"
            def buildTime = sdf.format(date)
            def buildTimeFormatted = buildTime
            def durationSec = (System.currentTimeMillis() - currentBuild.startTimeInMillis) / 1000
            // Read the Trivy report and summarize the findings
            //def trivyReport = readJSON file: 'trivy-report.json'
            
           
            // Debugging: Print the trivy report to verify the structure
            //echo "Trivy Report: ${trivyReport}"

    // Extract CRITICAL and HIGH vulnerabilities count
            //def criticalCount = trivyReport.Results?.collect { it.Vulnerabilities?.findAll { it.Severity == 'CRITICAL' } }?.flatten()?.size() ?: 0
           // def highCount = trivyReport.Results?.collect { it.Vulnerabilities?.findAll { it.Severity == 'HIGH' } }?.flatten()?.size() ?: 0

    // Debugging: Print the vulnerability counts to verify the calculation
            //echo "Critical Count: ${criticalCount}, High Count: ${highCount}"

           // def vulnerabilitySummary = "CRITICAL vulnerabilities: ${criticalCount}\nHIGH vulnerabilities: ${highCount}"
            def fileLinkjson = "https://storage.googleapis.com/${bucket_name}/trivy-reports/${gitCommitSHA}_trivy-report.json"
            //def fileLinkhtml = "https://storage.googleapis.com/${bucket_name}/image/${gitCommitSHA}_image.html"
            def fileLinkZap = "https://storage.googleapis.com/${bucket_name}/zap-reports/${gitCommitSHA}_zap_report.html"


            
            notifySlack("", slackNotificationChannel, [
                [
                    title: "${jobName}, build #${env.BUILD_NUMBER}",
                    title_link: "${env.BUILD_URL}",
                    color: "${buildColor}",
                    //text: "Build Status: \t${buildStatus}\nDeployer: \t${BUILD_TRIGGER_BY}\nEnvironment: \t${target_env}\n\nVulnerabilities Summary:\n${vulnerabilitySummary}\n\n[Click here to view report in json](${fileLinkjson})\n\n[Click here to view ZAP OWASP report](${fileLinkZap})",
                    text: "Build Status: \t${buildStatus}\nDeployer: \t${BUILD_TRIGGER_BY}\nEnvironment: \t${target_env}\n\n[Click here to view ZAP OWASP report](${fileLinkZap})",
                    "mrkdwn_in": ["fields"],
                    fields: [
                        [ title: "Branch", value: "${branch}", short: false ],
                        [ title: "Component", value: "${component}", short: false ],
                        [ title: "Deployment time", value: "${buildTime}", short: false ]
                    ]
                ]
            ])
            // Structured deployment log JSON
            def deployLog = [
                build: [
                    number: env.BUILD_NUMBER,
                    url: env.BUILD_URL,
                    job_name: env.JOB_NAME,
                    status: currentBuild.result ?: "SUCCESS",
                    trigger: BUILD_TRIGGER_BY,
                    started_at: buildTimeFormatted,
                    duration_sec: durationSec
                ],
                git: [
                    sha: gitCommitSHA,
                    branch: branch,
                ],
                deploy: [
                    environment: target_env,
                    docker_image: "$docker_repo:$gitCommitSHA"
                ],
                reports: [
                    trivy_json: "https://storage.googleapis.com/${bucket_name}/trivy-reports/${gitCommitSHA}_trivy-report.json",
                    zap_html: "https://storage.googleapis.com/${bucket_name}/zap-reports/${gitCommitSHA}_zap_report.html"
                ],
                triggered_by: BUILD_TRIGGER_BY
            ]
            auditLog.build = [
                number: env.BUILD_NUMBER,
                url: env.BUILD_URL,
                job_name: env.JOB_NAME,
                status: currentBuild.result ?: "SUCCESS",
                trigger: BUILD_TRIGGER_BY,
                started_at: buildTimeFormatted,
                duration_sec: durationSec
            ]
            if (suspiciousFlags.size() > 0) {
                //auditLog.suspicious_activity.flags = suspiciousFlags
                auditLog.suspicious_activity.timestamp = sdf.format(new Date())

                notifySlack(":warning: *Suspicious Activity Detected* in Pipeline", slackNotificationChannel, [
                    [
                        title: "Suspicious Activity - Build #${env.BUILD_NUMBER}",
                        text: suspiciousFlags.join("\n"),
                        color: "#FFA500"
                    ]
                ])
            }

            writeFile file: 'deploy-log.json', text: JsonOutput.prettyPrint(JsonOutput.toJson(deployLog))
            archiveArtifacts artifacts: 'deploy-log.json', allowEmptyArchive: true
            writeFile file: 'audit-log.json', text: JsonOutput.prettyPrint(JsonOutput.toJson(auditLog))
            archiveArtifacts artifacts: 'audit-log.json', allowEmptyArchive: true
        
        }

    }  catch (e) {
        currentBuild.result = "FAILURE"
        def buildStatus = "Fail"
        def buildColor = "#FF0000"
        def jobName = "${env.JOB_NAME}"
        def buildTime = sdf.format(date)

        notifySlack("", slackNotificationChannel, [
            [
                title: "${jobName}, build #${env.BUILD_NUMBER}",
                title_link: "${env.BUILD_URL}",
                color: "${buildColor}",
                text: "Build Status: \t${buildStatus}\nDeployer: \t${BUILD_TRIGGER_BY}\nEnvironment: \t${target_env}",
                fields: [
                    [ title: "Branch", value: "${branch}", short: false ],
                    [ title: "Component", value: "${component}", short: false ],
                    [ title: "Deployment time", value: "${buildTime}", short: false ]
                ]
            ]
        ])
        throw e
    }
}
